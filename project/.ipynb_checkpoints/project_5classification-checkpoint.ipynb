{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data_path, label_path):\n",
    "    #labels\n",
    "    labels = []\n",
    "    with open(label_path, 'r', encoding='utf-8') as trainLabel:\n",
    "        for label in trainLabel:\n",
    "            labels.append(int(re.sub(r'\\n', '', label)))\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    sentences = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as trainData:\n",
    "        for sentence in trainData:\n",
    "            sentences.append(re.sub(r'(<br /><br />)|(-.*?-)', ' ', sentence))\n",
    "    \n",
    "    #sentences\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = re.sub(r'[\"\\')\\(\\*\\.,!?``:;]| \\n', '', sentences[i]).split(' ')\n",
    "        #变为小写,词形还原\n",
    "        for j, word in enumerate(sentences[i]):\n",
    "            sentences[i][j] = stemmer.stem(word.lower())\n",
    "    \n",
    "    #除去停用词\n",
    "    stop_word_list2 = []\n",
    "    with open('data/stop_word2.txt', 'r', encoding='utf-8') as st:\n",
    "        stop_word_list2 = st.read().split('\\n')\n",
    "        \n",
    "    for sentence in sentences:\n",
    "        for word in sentence.copy():\n",
    "            if word in stop_word_list2:\n",
    "                sentence.remove(word)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, labels = data_preprocessing('data/5/trainData.txt', 'data/5/trainLabel.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成新的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/5/5_new_train.pkl', 'wb') as nt:\n",
    "    pickle.dump(sentences, nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/5/5_new_train.pkl', 'rb') as nt:\n",
    "    sentences = pickle.load(nt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: 1.0\n",
      "label: 2 2\n",
      "similarity: 0.8362449\n",
      "label: 2 3\n",
      "similarity: 0.75267655\n",
      "label: 2 0\n",
      "similarity: 0.7636352\n",
      "label: 2 4\n",
      "similarity: 0.44443733\n",
      "label: 2 2\n",
      "similarity: 0.8459352\n",
      "label: 2 4\n",
      "similarity: 0.6981785\n",
      "label: 2 4\n",
      "similarity: 0.76213104\n",
      "label: 2 2\n",
      "similarity: 0.81456167\n",
      "label: 2 1\n",
      "similarity: 0.5252778\n",
      "label: 2 3\n",
      "similarity: 0.54591596\n",
      "label: 2 0\n",
      "similarity: 0.8151882\n",
      "label: 2 4\n",
      "similarity: 0.6986904\n",
      "label: 2 3\n",
      "similarity: 0.6273449\n",
      "label: 2 3\n",
      "similarity: 0.8459405\n",
      "label: 2 4\n",
      "similarity: 0.6300418\n",
      "label: 2 4\n",
      "similarity: 0.71485186\n",
      "label: 2 3\n",
      "similarity: 0.77421886\n",
      "label: 2 4\n",
      "similarity: 0.6536436\n",
      "label: 2 3\n",
      "similarity: 0.7176421\n",
      "label: 2 3\n",
      "similarity: 0.71228427\n",
      "label: 2 1\n",
      "similarity: 0.7901938\n",
      "label: 2 0\n",
      "similarity: 0.6827219\n",
      "label: 2 1\n",
      "similarity: 0.7213849\n",
      "label: 2 3\n",
      "similarity: 0.6457514\n",
      "label: 2 4\n",
      "similarity: 0.60576767\n",
      "label: 2 3\n",
      "similarity: 0.79708546\n",
      "label: 2 3\n",
      "similarity: 0.67560965\n",
      "label: 2 2\n",
      "similarity: 0.8136377\n",
      "label: 2 3\n",
      "similarity: 0.59769946\n",
      "label: 2 4\n",
      "similarity: 0.8168344\n",
      "label: 2 3\n",
      "similarity: 0.80091727\n",
      "label: 2 2\n",
      "similarity: 0.64625806\n",
      "label: 2 0\n",
      "similarity: 0.77672064\n",
      "label: 2 4\n",
      "similarity: 0.69398546\n",
      "label: 2 4\n",
      "similarity: 0.9202534\n",
      "label: 2 0\n",
      "similarity: 0.7912843\n",
      "label: 2 1\n",
      "similarity: 0.77639097\n",
      "label: 2 4\n",
      "similarity: 0.7684952\n",
      "label: 2 1\n",
      "similarity: 0.6374106\n",
      "label: 2 4\n",
      "similarity: 0.77405965\n",
      "label: 2 2\n",
      "similarity: 0.7695414\n",
      "label: 2 2\n",
      "similarity: 0.65423524\n",
      "label: 2 1\n",
      "similarity: 0.8032251\n",
      "label: 2 2\n",
      "similarity: 0.69215\n",
      "label: 2 1\n",
      "similarity: 0.7142753\n",
      "label: 2 3\n",
      "similarity: 0.77175754\n",
      "label: 2 4\n",
      "similarity: 0.7489514\n",
      "label: 2 3\n",
      "similarity: 0.8167254\n",
      "label: 2 2\n",
      "similarity: 0.7626294\n",
      "label: 2 1\n",
      "similarity: 0.65422726\n",
      "label: 2 2\n",
      "similarity: 0.87250125\n",
      "label: 2 3\n",
      "similarity: 0.7129552\n",
      "label: 2 4\n",
      "similarity: 0.89246774\n",
      "label: 2 1\n",
      "similarity: 0.68581766\n",
      "label: 2 2\n",
      "similarity: 0.8329512\n",
      "label: 2 3\n",
      "similarity: 0.7294258\n",
      "label: 2 3\n",
      "similarity: 0.83004165\n",
      "label: 2 3\n",
      "similarity: 0.8171376\n",
      "label: 2 0\n",
      "similarity: 0.5502836\n",
      "label: 2 1\n",
      "similarity: 0.62347686\n",
      "label: 2 3\n",
      "similarity: 0.87790006\n",
      "label: 2 2\n",
      "similarity: 0.56731164\n",
      "label: 2 3\n",
      "similarity: 0.5992673\n",
      "label: 2 3\n",
      "similarity: 0.78393316\n",
      "label: 2 4\n",
      "similarity: 0.6157008\n",
      "label: 2 4\n",
      "similarity: 0.61795205\n",
      "label: 2 4\n",
      "similarity: 0.8505452\n",
      "label: 2 2\n",
      "similarity: 0.61483556\n",
      "label: 2 3\n",
      "similarity: 0.7581387\n",
      "label: 2 1\n",
      "similarity: 0.7072078\n",
      "label: 2 3\n",
      "similarity: 0.7810056\n",
      "label: 2 2\n",
      "similarity: 0.6240577\n",
      "label: 2 3\n",
      "similarity: 0.93806654\n",
      "label: 2 1\n",
      "similarity: 0.54490197\n",
      "label: 2 4\n",
      "similarity: 0.62319624\n",
      "label: 2 3\n",
      "similarity: 0.6736952\n",
      "label: 2 1\n",
      "similarity: 0.8810908\n",
      "label: 2 2\n",
      "similarity: 0.8256832\n",
      "label: 2 0\n",
      "similarity: 0.6487535\n",
      "label: 2 1\n",
      "similarity: 0.7838379\n",
      "label: 2 0\n",
      "similarity: 0.45377132\n",
      "label: 2 3\n",
      "similarity: 0.551526\n",
      "label: 2 1\n",
      "similarity: 0.78178513\n",
      "label: 2 0\n",
      "similarity: 0.68641365\n",
      "label: 2 2\n",
      "similarity: 0.6245769\n",
      "label: 2 0\n",
      "similarity: 0.70679593\n",
      "label: 2 4\n",
      "similarity: 0.63084483\n",
      "label: 2 0\n",
      "similarity: 0.6886242\n",
      "label: 2 1\n",
      "similarity: 0.5875913\n",
      "label: 2 4\n",
      "similarity: 0.6911511\n",
      "label: 2 4\n",
      "similarity: 0.7536647\n",
      "label: 2 2\n",
      "similarity: 0.68347365\n",
      "label: 2 4\n",
      "similarity: 0.87830925\n",
      "label: 2 1\n",
      "similarity: 0.8678289\n",
      "label: 2 0\n",
      "similarity: 0.77381694\n",
      "label: 2 1\n",
      "similarity: 0.7403138\n",
      "label: 2 0\n",
      "similarity: 0.7225084\n",
      "label: 2 3\n",
      "similarity: 0.5697262\n",
      "label: 2 4\n",
      "similarity: 0.8798195\n",
      "label: 2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `n_similarity` (Method will be removed in 4.0.0, use self.wv.n_similarity() instead).\n",
      "  \n",
      "/home/pp/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print('similarity:',model.n_similarity(sentences[0], sentences[i]))\n",
    "    print('label:', labels[0], labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取所有单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watch',\n",
       " 'movi',\n",
       " 'netflix',\n",
       " 'disc',\n",
       " 'mom',\n",
       " 'enjoy',\n",
       " 'thriller',\n",
       " 'agent',\n",
       " 'dure',\n",
       " '60s',\n",
       " 'tri',\n",
       " 'bring',\n",
       " 'trial',\n",
       " 'nazi',\n",
       " 'war',\n",
       " 'crimin',\n",
       " 'gynecologist',\n",
       " 'woman',\n",
       " 'rachel',\n",
       " 'jessica',\n",
       " 'chastain',\n",
       " 'pose',\n",
       " 'patient',\n",
       " 'complic',\n",
       " 'ensu',\n",
       " 'result',\n",
       " 'anoth',\n",
       " 'timelin',\n",
       " '30',\n",
       " 'helen',\n",
       " 'mirren',\n",
       " 'play',\n",
       " 'guilt',\n",
       " 'fellow',\n",
       " 'deal',\n",
       " 'haunt',\n",
       " 'quit',\n",
       " 'entertain',\n",
       " 'especi',\n",
       " 'scene',\n",
       " 'ms',\n",
       " 'doctor',\n",
       " 'talk',\n",
       " 'befor',\n",
       " 'debt',\n",
       " 'recommend',\n",
       " 'figur',\n",
       " 'larger',\n",
       " 'life',\n",
       " 'edgar',\n",
       " 'hoover',\n",
       " 'rank',\n",
       " 'career',\n",
       " 'span',\n",
       " '55',\n",
       " '1917',\n",
       " 'death',\n",
       " '1972',\n",
       " 'age',\n",
       " '77',\n",
       " 'leonardo',\n",
       " 'dicaprio',\n",
       " 'perform',\n",
       " 'lifetim',\n",
       " 'bull',\n",
       " 'dog',\n",
       " 'forg',\n",
       " 'sleepi',\n",
       " 'feder',\n",
       " 'agenc',\n",
       " 'premier',\n",
       " 'law',\n",
       " 'enforc',\n",
       " 'master',\n",
       " 'art',\n",
       " 'scientif',\n",
       " 'detect',\n",
       " 'onli',\n",
       " 'actor',\n",
       " 'jimmi',\n",
       " 'cagney',\n",
       " 'lrb',\n",
       " 'rrb',\n",
       " 'assum',\n",
       " 'air',\n",
       " 'profession',\n",
       " 'dissect',\n",
       " 'crime',\n",
       " 'arm',\n",
       " 'time',\n",
       " 'hero',\n",
       " 'villain',\n",
       " 'express',\n",
       " 'reserv',\n",
       " 'investig',\n",
       " 'nt',\n",
       " 'idea',\n",
       " 'summarili',\n",
       " 'dismiss',\n",
       " 'friend',\n",
       " 'real',\n",
       " 'american',\n",
       " 'damag',\n",
       " 'palmer',\n",
       " 'raid',\n",
       " 'alli',\n",
       " 'ensur',\n",
       " 'mani',\n",
       " 'culprit',\n",
       " 'belong',\n",
       " '1910s',\n",
       " 'excess',\n",
       " 'roar',\n",
       " 'twenti',\n",
       " 'cement',\n",
       " 'fbi',\n",
       " 'posit',\n",
       " 'nation',\n",
       " 'identif',\n",
       " 'kidnapp',\n",
       " 'bureau',\n",
       " 'simpl',\n",
       " 'task',\n",
       " 'accomplish',\n",
       " 'despit',\n",
       " 'botch',\n",
       " 'jersey',\n",
       " 'polic',\n",
       " 'interfer',\n",
       " 'charl',\n",
       " 'process',\n",
       " 'invent',\n",
       " 'close',\n",
       " 'smoke',\n",
       " 'loung',\n",
       " 'dr',\n",
       " 'albert',\n",
       " 'osborn',\n",
       " '230',\n",
       " 'class',\n",
       " 'teach',\n",
       " 'consid',\n",
       " 'pay',\n",
       " 'doubl',\n",
       " 'countri',\n",
       " 'congratul',\n",
       " 'brilliant',\n",
       " 'alway',\n",
       " 'self-promot',\n",
       " 'claim',\n",
       " 'contrari',\n",
       " 'secret',\n",
       " 'fund',\n",
       " 'favor',\n",
       " 'fed',\n",
       " 'rise',\n",
       " 'myth',\n",
       " 'washington',\n",
       " 'solv',\n",
       " 'local',\n",
       " 'eye',\n",
       " 'polit',\n",
       " 'politician',\n",
       " 'maintain',\n",
       " 'fiefdom',\n",
       " 'nixon',\n",
       " 'confidenti',\n",
       " 'file',\n",
       " 'film',\n",
       " 'drag',\n",
       " 'howev',\n",
       " 'clint',\n",
       " 'eastwood',\n",
       " 'spin',\n",
       " 'mob',\n",
       " 'warfar',\n",
       " '1920s',\n",
       " 'apprehens',\n",
       " 'notori',\n",
       " 'bad',\n",
       " 'guy',\n",
       " 'cut',\n",
       " 'mafia',\n",
       " 'lid',\n",
       " 'gun',\n",
       " 'battl',\n",
       " 'kidnap',\n",
       " 'bank',\n",
       " 'robberi',\n",
       " 'preval',\n",
       " 'public',\n",
       " 'deni',\n",
       " 'exist',\n",
       " 'quirki',\n",
       " 'comedi',\n",
       " 'offic',\n",
       " 'worker',\n",
       " 'discov',\n",
       " 'passag',\n",
       " 'somewher',\n",
       " 'insid',\n",
       " 'john',\n",
       " 'malkovitch',\n",
       " 'head',\n",
       " 'proceed',\n",
       " 'hilari',\n",
       " 'love',\n",
       " 'triangl',\n",
       " 'over-r',\n",
       " 'anyth',\n",
       " 'deep',\n",
       " 'cult',\n",
       " 'hit',\n",
       " 'lesli',\n",
       " 'howard',\n",
       " 'superb',\n",
       " 'english',\n",
       " 'fop',\n",
       " 'sir',\n",
       " 'perci',\n",
       " 'realiti',\n",
       " 'dread',\n",
       " 'scarlet',\n",
       " 'pimpernel',\n",
       " 'rescu',\n",
       " 'french',\n",
       " 'nobil',\n",
       " 'hand',\n",
       " 'robespierr',\n",
       " 'henchmen',\n",
       " 'merl',\n",
       " 'oberon',\n",
       " 'excel',\n",
       " 'beauti',\n",
       " 'unknow',\n",
       " 'wife',\n",
       " 'raymond',\n",
       " 'massey',\n",
       " 'memor',\n",
       " 'evil',\n",
       " 'goon',\n",
       " 'everyth',\n",
       " 'ident',\n",
       " 'nigel',\n",
       " 'bruce',\n",
       " 'princ',\n",
       " 'wale',\n",
       " 'joan',\n",
       " 'gardner',\n",
       " 'mabel',\n",
       " 'women',\n",
       " 'melvill',\n",
       " 'cooper',\n",
       " 'painter',\n",
       " 'bramwel',\n",
       " 'fletcher',\n",
       " 'priest',\n",
       " 'anthoni',\n",
       " 'bushel',\n",
       " 'role',\n",
       " 'gorgeous',\n",
       " 'design',\n",
       " 'direct',\n",
       " 'rock',\n",
       " 'solid',\n",
       " 'script',\n",
       " 'lightn',\n",
       " 'fast',\n",
       " 'fill',\n",
       " 'wit',\n",
       " 'banter',\n",
       " 'includ',\n",
       " 'famous',\n",
       " 'poem',\n",
       " 'recit',\n",
       " 'sever',\n",
       " 'piec',\n",
       " 've',\n",
       " 'total',\n",
       " 'delight',\n",
       " 'faux',\n",
       " 'minc',\n",
       " 'fashion',\n",
       " 'spout',\n",
       " 'bit',\n",
       " 'poetri',\n",
       " 'fun',\n",
       " 'bewild',\n",
       " 'breathtak',\n",
       " 'closeup',\n",
       " 'anyon',\n",
       " 'sinist',\n",
       " 'smile',\n",
       " 'lot',\n",
       " 'scienc',\n",
       " 'fiction',\n",
       " 'base',\n",
       " 'veri',\n",
       " 'familiar',\n",
       " 'simplist',\n",
       " 'plot',\n",
       " 'nice',\n",
       " 'sci',\n",
       " 'fi',\n",
       " 'fan',\n",
       " 'pleas',\n",
       " 'everyon',\n",
       " 'fred',\n",
       " 'zinnemann',\n",
       " 'etern',\n",
       " 'david',\n",
       " 'lean',\n",
       " 'bridg',\n",
       " 'river',\n",
       " 'kwai',\n",
       " 'common',\n",
       " 'stori',\n",
       " 'peopl',\n",
       " 'extrem',\n",
       " 'identifi',\n",
       " 'concern',\n",
       " 'strang',\n",
       " 'sinc',\n",
       " 'militari',\n",
       " 'peacetim',\n",
       " 'armi',\n",
       " 'import',\n",
       " 'motion',\n",
       " 'pictur',\n",
       " 'decemb',\n",
       " '1941',\n",
       " 'japanes',\n",
       " 'attack',\n",
       " 'pearl',\n",
       " 'harbor',\n",
       " 'definit',\n",
       " 'explos',\n",
       " 'ruthless',\n",
       " 'mind',\n",
       " 'sequenc',\n",
       " 'sound',\n",
       " 'plane',\n",
       " 'heard',\n",
       " 'confus',\n",
       " 'soldier',\n",
       " 'earli',\n",
       " 'breakfast',\n",
       " 'bomber',\n",
       " 'dive',\n",
       " 'sweep',\n",
       " 'fire',\n",
       " 'machin',\n",
       " 'fight',\n",
       " 'companion',\n",
       " 'refus',\n",
       " 'pass',\n",
       " 'pal',\n",
       " 'break',\n",
       " 'door',\n",
       " 'ammunit',\n",
       " 'roof',\n",
       " 'fli',\n",
       " 'succeed',\n",
       " 'flavor',\n",
       " 'power',\n",
       " 'connect',\n",
       " 'hold',\n",
       " 'togeth',\n",
       " 'charact',\n",
       " 'perman',\n",
       " 'alter',\n",
       " 'event',\n",
       " 'reduc',\n",
       " 'pain',\n",
       " 'passion',\n",
       " 'ii',\n",
       " 'forc',\n",
       " 'modifi',\n",
       " 'bigger',\n",
       " 'highlight',\n",
       " 'mention',\n",
       " 'clift',\n",
       " 'flamboy',\n",
       " 'blue',\n",
       " 'beer',\n",
       " 'joint',\n",
       " 'rush',\n",
       " 'expel',\n",
       " 'bodi',\n",
       " 'strength',\n",
       " 'feel',\n",
       " 'lancast',\n",
       " 'kerr',\n",
       " 'desert',\n",
       " 'beach',\n",
       " 'tap',\n",
       " 'tear',\n",
       " 'burt',\n",
       " 'portray',\n",
       " 'tough',\n",
       " 'effici',\n",
       " 'sergeant',\n",
       " 'bend',\n",
       " 'rule',\n",
       " 'guid',\n",
       " 'support',\n",
       " 'pretenti',\n",
       " 'captain',\n",
       " 'prove',\n",
       " 'inspir',\n",
       " 'leader',\n",
       " 'barrack',\n",
       " 'montgomeri',\n",
       " 'perhap',\n",
       " 'convict',\n",
       " 'stronger',\n",
       " 'treatment',\n",
       " 'deborah',\n",
       " 'cool',\n",
       " 'ladi',\n",
       " 'stimul',\n",
       " 'frank',\n",
       " 'sinatra',\n",
       " 'terrif',\n",
       " 'rebelli',\n",
       " 'angelo',\n",
       " 'maggio',\n",
       " 'intens',\n",
       " 'character',\n",
       " 'win',\n",
       " 'academi',\n",
       " 'award',\n",
       " 'donna',\n",
       " 'reed',\n",
       " 'charm',\n",
       " 'social',\n",
       " 'winner',\n",
       " 'indic',\n",
       " 'collis',\n",
       " 'destini',\n",
       " 'throw',\n",
       " 'violent',\n",
       " 'turbul',\n",
       " 'danger',\n",
       " 'situat',\n",
       " 'univers',\n",
       " 'monster',\n",
       " 'classic',\n",
       " 'incorpor',\n",
       " 'archeolog',\n",
       " 'creatur',\n",
       " 'black',\n",
       " 'lagoon',\n",
       " 'littl',\n",
       " 'hokey',\n",
       " 'nowaday',\n",
       " 'pleasur',\n",
       " 'titl',\n",
       " 'star',\n",
       " 'origin',\n",
       " 'piscin',\n",
       " 'amphibi',\n",
       " 'humanoid',\n",
       " 'recogniz',\n",
       " 'human',\n",
       " 'incurs',\n",
       " 'amazon',\n",
       " 'sympathi',\n",
       " 'lone',\n",
       " 'smitten',\n",
       " 'kay',\n",
       " 'julia',\n",
       " 'adam',\n",
       " 'jerk',\n",
       " 'mark',\n",
       " 'richard',\n",
       " 'den',\n",
       " 'kill',\n",
       " 'anim',\n",
       " 'cours',\n",
       " 'els',\n",
       " 'happen',\n",
       " 'corni',\n",
       " 'music',\n",
       " 'silli',\n",
       " 'dialogu',\n",
       " 'obvious',\n",
       " 'set',\n",
       " 'fine',\n",
       " 'rememb',\n",
       " 'swim',\n",
       " 'unknown',\n",
       " 'water',\n",
       " 'ashton',\n",
       " 'kutcher',\n",
       " 'realli',\n",
       " 'appeal',\n",
       " 'expect',\n",
       " 'pleasant',\n",
       " 'surpris',\n",
       " 'outstand',\n",
       " 'qualiti',\n",
       " 'troubl',\n",
       " 'unsettl',\n",
       " 'evan',\n",
       " 'minor',\n",
       " 'chang',\n",
       " 'walk',\n",
       " 'elm',\n",
       " 'street',\n",
       " 'll',\n",
       " 'mapl',\n",
       " 'possibl',\n",
       " 'impact',\n",
       " 'prevent',\n",
       " 'kayleigh',\n",
       " 'molest',\n",
       " 'mother',\n",
       " 'babi',\n",
       " 'substant',\n",
       " 'cliché',\n",
       " 'asid',\n",
       " 'truli',\n",
       " '8/10',\n",
       " '75',\n",
       " 'woodi',\n",
       " 'allen',\n",
       " 'sooth',\n",
       " 'slight',\n",
       " 'fiancé',\n",
       " 'inez',\n",
       " 'mcadam',\n",
       " 'snobbi',\n",
       " 'overbear',\n",
       " 'parent',\n",
       " 'kurt',\n",
       " 'fuller',\n",
       " 'mimmi',\n",
       " 'kennedi',\n",
       " 'continu',\n",
       " 'churn',\n",
       " 'formula',\n",
       " 'reliabl',\n",
       " 'profit',\n",
       " 'hollywood',\n",
       " 'current',\n",
       " 'decid',\n",
       " 'uncomfort',\n",
       " 'parisian',\n",
       " 'holiday',\n",
       " 'chanc',\n",
       " 'encount',\n",
       " 'overzeal',\n",
       " 'shoe',\n",
       " 'clumsi',\n",
       " 'protagonist',\n",
       " 'struggl',\n",
       " 'satisfi',\n",
       " 'hard',\n",
       " 'execut',\n",
       " 'decept',\n",
       " 'alfr',\n",
       " 'hitchcock',\n",
       " 'psycho',\n",
       " '1960',\n",
       " 'audienc',\n",
       " 'complet',\n",
       " 'unsuspect',\n",
       " 'gil',\n",
       " 'start',\n",
       " 'pablo',\n",
       " 'picasso',\n",
       " 'ernest',\n",
       " 'hemingway',\n",
       " 'eliot',\n",
       " 'scott',\n",
       " 'fitzgerald',\n",
       " 'fabul',\n",
       " 'night',\n",
       " 'golden',\n",
       " 'becom',\n",
       " 'regular',\n",
       " 'visitor',\n",
       " 'return',\n",
       " 'day',\n",
       " 'discoveri',\n",
       " 'fresh',\n",
       " 'send',\n",
       " 'loathsom',\n",
       " 'utter',\n",
       " 'bewilder',\n",
       " 'divert',\n",
       " 'rout',\n",
       " 'femal',\n",
       " 'spous',\n",
       " 'complain',\n",
       " 'obsess',\n",
       " 'male',\n",
       " 'appar',\n",
       " 'descent',\n",
       " 'mad',\n",
       " 'eventu',\n",
       " 'sens',\n",
       " 'butter',\n",
       " 'onc',\n",
       " 'becaus',\n",
       " 'relationship',\n",
       " 'paramount',\n",
       " 'matter',\n",
       " 'hole',\n",
       " 'patch',\n",
       " 'incess',\n",
       " 'whing',\n",
       " 'soar',\n",
       " 'height',\n",
       " 'effort',\n",
       " 'appeas',\n",
       " 'solac',\n",
       " 'adriana',\n",
       " 'marion',\n",
       " 'cotillard',\n",
       " 'adventur',\n",
       " 'soul',\n",
       " 'numer',\n",
       " 'muse',\n",
       " 'lover',\n",
       " 'dynam',\n",
       " 'genuin',\n",
       " 'wo',\n",
       " 'spoil',\n",
       " 'element',\n",
       " 'ad',\n",
       " 'unpromis',\n",
       " 'ingredi',\n",
       " 'smart',\n",
       " 'insight',\n",
       " 'conclus',\n",
       " 'nostalg',\n",
       " 'romantic',\n",
       " 'invit',\n",
       " 'era',\n",
       " 'doe',\n",
       " 'true',\n",
       " 'reveal',\n",
       " 'appreci',\n",
       " 'yearn',\n",
       " 'bliss',\n",
       " 'innoc',\n",
       " 'secur',\n",
       " 'allud',\n",
       " 'pari',\n",
       " 'perceiv',\n",
       " 'perfect',\n",
       " 'paradis',\n",
       " 'shot',\n",
       " 'mundan',\n",
       " 'imperfect',\n",
       " 'ani',\n",
       " 'western',\n",
       " 'citi',\n",
       " 'themat',\n",
       " 'materi',\n",
       " 'lift',\n",
       " 'abov',\n",
       " 'ordinari',\n",
       " 'standard',\n",
       " 'astut',\n",
       " 'control',\n",
       " '94',\n",
       " 'carla',\n",
       " 'bruni',\n",
       " 'kathi',\n",
       " 'bate',\n",
       " 'léa',\n",
       " 'seydoux',\n",
       " 'adrien',\n",
       " 'brodi',\n",
       " 'west',\n",
       " 'sergio',\n",
       " 'leon',\n",
       " 'bronson',\n",
       " 'claudia',\n",
       " 'cardinal',\n",
       " 'jason',\n",
       " 'robard',\n",
       " '&',\n",
       " 'henri',\n",
       " 'fonda',\n",
       " 'rrb-',\n",
       " 'call',\n",
       " 'masterpiec',\n",
       " 'sourc',\n",
       " 'darn',\n",
       " 'uncut',\n",
       " 'form',\n",
       " 'repeat',\n",
       " 'view',\n",
       " 'reward',\n",
       " 'dilut',\n",
       " '9/10',\n",
       " 'featur',\n",
       " 'cast',\n",
       " 'creepi',\n",
       " 'entir',\n",
       " 'explain',\n",
       " 'resembl',\n",
       " 'allan',\n",
       " 'poe',\n",
       " 'short',\n",
       " 'main',\n",
       " 'touch',\n",
       " 'remind',\n",
       " 'folk',\n",
       " 'frankenstein',\n",
       " 'type',\n",
       " 'period',\n",
       " 'lack',\n",
       " 'soundtrack',\n",
       " 'technolog',\n",
       " 'crude',\n",
       " 'extra',\n",
       " 'viewer',\n",
       " 'creepier',\n",
       " 'normal',\n",
       " 'scream',\n",
       " 'besid',\n",
       " 'bela',\n",
       " 'compar',\n",
       " 'dracula',\n",
       " 'arlen',\n",
       " 'franci',\n",
       " 'queen',\n",
       " 'game',\n",
       " 'panel',\n",
       " 'tv',\n",
       " 'rocki',\n",
       " 'favorit',\n",
       " 'boy',\n",
       " '70s',\n",
       " '80s',\n",
       " 'trilog',\n",
       " 'amaz',\n",
       " 'ring',\n",
       " 'apollo',\n",
       " 'boxer',\n",
       " 'courag',\n",
       " 'beat',\n",
       " 'balboa',\n",
       " 'naiv',\n",
       " 'heart',\n",
       " 'booki',\n",
       " 'bet',\n",
       " 'collector',\n",
       " 'earn',\n",
       " 'money',\n",
       " 'wise',\n",
       " 'coach',\n",
       " 'spend',\n",
       " 'box',\n",
       " 'collect',\n",
       " 'hang',\n",
       " 'annoy',\n",
       " 'pauli',\n",
       " 'shi',\n",
       " 'adrianna',\n",
       " 'sister',\n",
       " 'unexpect',\n",
       " 'opportun',\n",
       " 'champion',\n",
       " 'creed',\n",
       " 'cheer',\n",
       " 'mine',\n",
       " 'russel',\n",
       " 'crow',\n",
       " 'gladiat',\n",
       " 'check',\n",
       " 'oscar',\n",
       " 'de-forc',\n",
       " 'welcom',\n",
       " 'genr',\n",
       " 'usual',\n",
       " 'suspend',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'incred',\n",
       " 'understand',\n",
       " 'truth',\n",
       " 'train',\n",
       " 'modern',\n",
       " 'sceneri',\n",
       " 'coher',\n",
       " 'suspens',\n",
       " 'le',\n",
       " 'voyag',\n",
       " 'dan',\n",
       " 'la',\n",
       " 'lune',\n",
       " 'earlier',\n",
       " '1902',\n",
       " 'exclus',\n",
       " 'camera',\n",
       " 'record',\n",
       " 'activ',\n",
       " 'middl',\n",
       " 'snippet',\n",
       " 'action',\n",
       " 'whop',\n",
       " 'ten',\n",
       " 'minut',\n",
       " 'signific',\n",
       " 'averag',\n",
       " 'pretti',\n",
       " 'watchabl',\n",
       " 'decent',\n",
       " 'indoor',\n",
       " 'outdoor',\n",
       " '-',\n",
       " 'attempt',\n",
       " 'forgiv',\n",
       " 'alik',\n",
       " 'meryl',\n",
       " 'streep',\n",
       " 'wrong',\n",
       " 'purs',\n",
       " 'davi',\n",
       " 'assur',\n",
       " 'wind',\n",
       " 'late',\n",
       " 'ravish',\n",
       " 'british',\n",
       " 'vivien',\n",
       " 'leigh',\n",
       " 'swipe',\n",
       " 'enter',\n",
       " 'immort',\n",
       " 'addit',\n",
       " 'credit',\n",
       " 'live',\n",
       " 'socialit',\n",
       " 'judith',\n",
       " 'trahern',\n",
       " 'popular',\n",
       " 'circl',\n",
       " 'altern',\n",
       " 'loath',\n",
       " 'lust',\n",
       " 'strike',\n",
       " 'independ',\n",
       " 'fate',\n",
       " 'tricki',\n",
       " 'step',\n",
       " 'visit',\n",
       " 'fall',\n",
       " 'hors',\n",
       " 'lead',\n",
       " 'revel',\n",
       " 'threaten',\n",
       " 'someth',\n",
       " 'spitfir',\n",
       " 'furi',\n",
       " 'deck',\n",
       " 'card',\n",
       " 'stack',\n",
       " 'loyal',\n",
       " 'georg',\n",
       " 'brent',\n",
       " 'brutal',\n",
       " 'honest',\n",
       " 'treat',\n",
       " 'uniqu',\n",
       " 'bogart',\n",
       " 'lusti',\n",
       " 'ronni',\n",
       " 'reagan',\n",
       " 'sector',\n",
       " 'boyfriend',\n",
       " 'spirit',\n",
       " 'sexless',\n",
       " 'heathcliff',\n",
       " 'match',\n",
       " 'sexual',\n",
       " 'equal',\n",
       " 'seduct',\n",
       " 'circumst',\n",
       " 'stabl',\n",
       " 'romant',\n",
       " 'noteworthi',\n",
       " 'geraldin',\n",
       " 'secretari',\n",
       " 'confidant',\n",
       " 'stand',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'grow',\n",
       " 'devil',\n",
       " 'care',\n",
       " 'ultim',\n",
       " 'doom',\n",
       " 'ton',\n",
       " 'everi',\n",
       " 'mortal',\n",
       " 'digniti',\n",
       " 'superhero',\n",
       " 'cultur',\n",
       " 'centuri',\n",
       " 'ardent',\n",
       " 'reason',\n",
       " 'whi',\n",
       " 'batman',\n",
       " 'score',\n",
       " 'subtl',\n",
       " 'somber',\n",
       " 'excit',\n",
       " 'move',\n",
       " 'steadi',\n",
       " 'pace',\n",
       " 'slow',\n",
       " 'pick',\n",
       " 'choreograph',\n",
       " 'stunt',\n",
       " 'cgi',\n",
       " 'memori',\n",
       " 'con',\n",
       " 'mayb',\n",
       " 'shave',\n",
       " 'final',\n",
       " 'afterward',\n",
       " 'impress',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'relat',\n",
       " 'plain',\n",
       " 'franchis',\n",
       " 'glad',\n",
       " 'track',\n",
       " 'dark',\n",
       " 'knight',\n",
       " 'rate',\n",
       " '5/5',\n",
       " 'cinema',\n",
       " 'gauch',\n",
       " 'miracl',\n",
       " 'suppos',\n",
       " 'artist',\n",
       " 'aspir',\n",
       " 'dream',\n",
       " 'writer',\n",
       " '20s',\n",
       " '30s',\n",
       " 'previous',\n",
       " 'magic',\n",
       " 'citroen',\n",
       " 'midnight',\n",
       " 'meet',\n",
       " 'idol',\n",
       " 'dali',\n",
       " 'gertrud',\n",
       " 'stein',\n",
       " 'modigliani',\n",
       " '21st',\n",
       " '19th',\n",
       " 'nobodi',\n",
       " 'astonish',\n",
       " 'fluiditi',\n",
       " 'sentiment',\n",
       " 'ration',\n",
       " 'mechan',\n",
       " 'explan',\n",
       " 'behav',\n",
       " 'exact',\n",
       " 'describ',\n",
       " 'text',\n",
       " 'represent',\n",
       " 'question',\n",
       " 'trigger',\n",
       " 'screen',\n",
       " 'theater',\n",
       " 'everybodi',\n",
       " 'unhappi',\n",
       " 'seek',\n",
       " 'refug',\n",
       " 'shine',\n",
       " 'perspect',\n",
       " 'histori',\n",
       " 'omnipres',\n",
       " 'provid',\n",
       " 'presenc',\n",
       " 'declar',\n",
       " 'seri',\n",
       " 'postcard',\n",
       " 'tourist',\n",
       " 'content',\n",
       " 'kingdom',\n",
       " 'mirror',\n",
       " 'didact',\n",
       " 'messag',\n",
       " 'enhanc',\n",
       " 'somebodi',\n",
       " 'song',\n",
       " 'hear',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word = []\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        if word not in all_word:\n",
    "            all_word.append(word)\n",
    "all_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算TF矩阵\n",
    "tf = np.zeros((len(sentences), len(all_word)), dtype=bool) #(24000,38710)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for word in sentence:\n",
    "        index = all_word.index(word)\n",
    "        tf[i][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38710"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = 20000\n",
    "train_data = tf[:train_length]\n",
    "train_labels = labels[:train_length]\n",
    "validation_data = sentences[train_length:]\n",
    "validation_labels = labels[train_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_word_by_kf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-404a06c47dc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_word_by_kf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mtrain_one_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_word_by_kf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_word_by_kf' is not defined"
     ]
    }
   ],
   "source": [
    "train_one_hot = np.zeros((len(sentences), len(all_word_by_kf)), dtype='int8')\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            train_one_hot[i][all_word_by_kf.index(word)] += 1\n",
    "        except:\n",
    "            train_one_hot[-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-875ff3c8a210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mX_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mX_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mX_std\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m--> 140\u001b[0;31m                keepdims=keepdims)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
